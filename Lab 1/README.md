# Deep-Learning-and-Practice Lab 1
🚀 Back propagation  
🏹 The goal of this lab is to implement neural network without framework library (e.g., Pytorch etc.).



## Arguments
|Argument|Description|Default|
|---|---|---|
|`'-d', '--data_type'`|0: linear data points, 1: XOR data points|0|
|`'-n', '--number_of_data'`|Number of data points|100|
|`'-e', '--epoch'`|Number of epoch|1000000|
|`'-l', '--learning-rate'`|Learning rate of the neural network|0.1|
|`'-u', '--units'`|Number of units in each hidden layer|4|
|`'-a', '--activation'`|Type of activation function|'sigmoid'|
|`'-o', '--optimizer'`|Type of optimizer|'gd'|